<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="/favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<title>Purple Interviews - Data</title>

		

		<link rel="modulepreload" href="/_app/start-6a8dc90b.js">
		<link rel="modulepreload" href="/_app/chunks/vendor-2e27399c.js">
		<link rel="modulepreload" href="/_app/chunks/paths-28a87002.js">
		<link rel="modulepreload" href="/_app/pages/__layout.svelte-f0d5aa20.js">
		<link rel="modulepreload" href="/_app/pages/[slug].svelte-72899930.js">
		<link rel="stylesheet" href="/_app/assets/start-464e9d0a.css">
		<link rel="stylesheet" href="/_app/assets/pages/__layout.svelte-58634277.css">

		<script type="module">
			import { start } from "/_app/start-6a8dc90b.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"","assets":""},
				session: {},
				host: location.host,
				route: true,
				spa: false,
				trailing_slash: "never",
				hydrate: {
					status: 200,
					error: null,
					nodes: [
						import("/_app/pages/__layout.svelte-f0d5aa20.js"),
						import("/_app/pages/[slug].svelte-72899930.js")
					],
					page: {
						host: location.host, // TODO this is redundant
						path: "/data",
						query: new URLSearchParams(""),
						params: {"slug":"data"}
					}
				}
			});
		</script>
	</head>
	<body>
		<div id="svelte">


<div><div class="filter drop-shadow-md bg-white"><nav class="border-t-2 border-solid border-red"><a href="/"><img src="/tplogo-red.svg" alt="Telstra Purple" class="px-12 lg:px-32 py-2 lg:py-4"></a></nav></div>
	<div class="px-12 lg:px-32 pt-6 lg:pt-24 pb-3 lg:pb-12"><div class="max-w-screen-xl flex flex-col"><div class="flex flex-col lg:flex-row"><div class="flex flex-col"><h1 class="pb-3 lg:pb-12">Purple Interviews</h1>
				<p class="max-w-prose">We&#39;re pleased to invite you to the testing stage of our Consultant roles at Telstra
					Purple. On this page you&#39;ll find instructions on how to complete the technical interview
					pre-requisites for the desired role you&#39;re looking to apply for.
					<br><br>
					Once you have completed the prescribed test, please send back your workings as instructed below.
					One of our consultants will then review and make a decision on whether you will progress to
					the next stage. Rest assured, we&#39;ll of course give you feedback either way.
					<br><br>
					If you&#39;re interested to see more roles at Telstra Purple, make sure to check out
					<a href="http://purple.telstra.com/careers" class="text-red">Telstra Purple Careers</a>.
					<br><br>
					To understand more about our role levels, check out our
					<a href="http://personas.purple.telstra.com/" class="text-red">Career Frameworks</a> page.
				</p></div>
			<img src="/interview.svg" alt="A person sitting at a desk with a laptop" class="max-h-300"></div>
		<h2 class="py-3 lg:pt-12 lg:pb-2">Interview for</h2>
			<div class="flex flex-col lg:flex-row justify-start flex-wrap"><a href="/cloud"><div class="rounded-lg px-5 py-2 bg-red text-white text-lg mr-4 mb-2 hover:bg-black">Cloud</div>
					</a><a href="/data"><div class="rounded-lg px-5 py-2 bg-red text-white text-lg mr-4 mb-2 hover:bg-black">Data</div>
					</a><a href="/development"><div class="rounded-lg px-5 py-2 bg-red text-white text-lg mr-4 mb-2 hover:bg-black">Development</div>
					</a><a href="/devops"><div class="rounded-lg px-5 py-2 bg-red text-white text-lg mr-4 mb-2 hover:bg-black">DevOps</div>
					</a></div></div></div>
	



<div class="px-12 lg:px-32 max-w-screen bg-gray"><h2 class="pb-4 lg:pb-4 text-black text-xl">Instructions for</h2>
	<div class="flex flex-col lg:flex-row justify-start pb-2 lg:pb-8"><a href="#data-analyst" class="text-red"><div class="rounded-lg px-5 py-2 bg-black text-white text-lg mr-4 mb-2 hover:bg-red">Data Analyst</div>
			</a><a href="#data-engineer" class="text-red"><div class="rounded-lg px-5 py-2 bg-black text-white text-lg mr-4 mb-2 hover:bg-red">Data Engineer</div>
			</a></div></div>
<div class="flex flex-col sm:flex-row px-12 lg:px-32 pt-4 pb-5 lg:pt-14 bg-gray-lighter"><article class="Interview"><!-- HTML_TAG_START --><h1 id="data-analyst"><a aria-hidden="true" tabindex="-1" href="#data-analyst"><span class="icon icon-link"></span></a>Data Analyst</h1>
<h2 id="prerequisites"><a aria-hidden="true" tabindex="-1" href="#prerequisites"><span class="icon icon-link"></span></a>Prerequisites</h2>
<p>In order to complete this test, you will need:</p>
<ol>
<li>Your laptop with <a rel="external" href="https://powerbi.microsoft.com/en-us/downloads/">Power BI Desktop</a> installed.</li>
<li>A public GitHub repo, or a Google/OneDrive where you can share your workings (E.g. Power BI files).</li>
</ol>
<h2 id="scenario"><a aria-hidden="true" tabindex="-1" href="#scenario"><span class="icon icon-link"></span></a>Scenario</h2>
<p>As the Data Analyst for a small fuel company, you have been given two (2) data sources.</p>
<ol>
<li><a rel="external" href="http://www.fuelwatch.wa.gov.au/fuelwatch/fuelWatchRSS">The FuelWatch RSS feed</a></li>
<li><a rel="external" href="/code/discount.xlsx">Discounts Excel file</a></li>
</ol>
<h2 id="instructions"><a aria-hidden="true" tabindex="-1" href="#instructions"><span class="icon icon-link"></span></a>Instructions</h2>
<p>You have been ask to create a Power BI report that combines both sources to answer questions the business may have around its competitors.</p>
<h3 id="modelling"><a aria-hidden="true" tabindex="-1" href="#modelling"><span class="icon icon-link"></span></a>Modelling</h3>
<ol>
<li>In Power BI, connect to the two (2) data sources.</li>
<li>Create three (3) new dimension tables - <strong>Brand</strong>, <strong>Site</strong> and <strong>SiteFeatures</strong>. They should have the respective attributes below.
<ul>
<li>BrandID , BrandName</li>
<li>SiteID , TradingName, Location, Address, Phone, Latitude, Longitude. Please also add a computed, persisted column named <strong><em>FullAddress</em></strong> which combines Address and Location.</li>
<li>SiteFeatureID , SiteID (From the Site table) and the various site features from the delimited source column site-features.</li>
</ul>
</li>
<li>Create a single fact table called FuelPrice. It should have the columns below:
<ul>
<li>FuelPriceID (Identity), BrandID (From the Branch table), SiteID (From the Site table), DateID (Numeric and stored as yyyymmdd), Price, DateCreated (Default to current system time) and DateModified (nullable, no default).</li>
</ul>
</li>
<li>Clean the data in Power BI by removing any uncesscary columns not mentioned above.</li>
</ol>
<h3 id="visualisation"><a aria-hidden="true" tabindex="-1" href="#visualisation"><span class="icon icon-link"></span></a>Visualisation</h3>
<ol>
<li>Create visuals using the modelled data that allow the business to answer the following questions.
<ul>
<li>When and where can they find the cheapest fuel after the is discount applied?</li>
<li>See a list of the top 10 sites with the cheapest fuel price?</li>
<li>Be able to drill-down into all the details for a the top 10 cheapest fuel stations?</li>
<li>Discover quickly which sites are open 24 hours a day?</li>
</ul>
</li>
</ol>
<p>The business executives have also asked for how a consistent theme can be applied to the report and other reports in the future.</p>
<h2 id="completion"><a aria-hidden="true" tabindex="-1" href="#completion"><span class="icon icon-link"></span></a>Completion</h2>
<p>When the solution is above is complete, save the PowerBI file and any supporting templates and share with the Consultant/ Talent Acquisition Specialist who contacted you from Telstra Purple.</p>
<h1 id="data-engineer"><a aria-hidden="true" tabindex="-1" href="#data-engineer"><span class="icon icon-link"></span></a>Data Engineer</h1>
<h2 id="prerequisites-1"><a aria-hidden="true" tabindex="-1" href="#prerequisites-1"><span class="icon icon-link"></span></a>Prerequisites</h2>
<p>Please build the platform on the cloud environment as nominated by the Consultant/ Talent Acquisition Specialist who has invited you to complete this test.</p>
<p>To complete this test, you will need:</p>
<ol>
<li>Access to a Cloud service provider environment.
<ul>
<li>For an Azure Subscription, you can create a <a rel="external" href="https://azure.microsoft.com/en-au/free/">30-day free trial</a> if you don't have an Azure subscription.</li>
<li>For an AWS Account, you can utilise <a rel="external" href="https://aws.amazon.com/free/">AWS free tier</a> if you don't have an AWS Account.</li>
<li>For an GCP Environment, you can utilise <a rel="external" href="https://cloud.google.com/free">GCP free tier</a> if you don't have an GCP Account.</li>
</ul>
</li>
<li>Your laptop with your tools/ IDE that you like to work with.</li>
<li>A public GitHub repo, or a Google/OneDrive where you can share your workings.</li>
</ol>
<h2 id="scenario-1"><a aria-hidden="true" tabindex="-1" href="#scenario-1"><span class="icon icon-link"></span></a>Scenario</h2>
<p>We are assisting a customer in building out a solution which ingests the latest fuel prices from the Fuel Watch RSS feed. This data is not in a great structure, and we would like to ingest this data into a data lake, perform some transformations and build out a data mart for use in Power BI, the customers visualisation tool of choice.</p>
<ol>
<li>Our customer would like to take an infrastructure-as-code approach to the deployment of the new resources however, the delivery of a working prototype is the highest priority.</li>
<li>All resources should be deployed in Australia.</li>
</ol>
<h2 id="instructions-1"><a aria-hidden="true" tabindex="-1" href="#instructions-1"><span class="icon icon-link"></span></a>Instructions</h2>
<p>Follow these instructions and deploy using whatever means you feel necessary.</p>
<h3 id="building-the-platform"><a aria-hidden="true" tabindex="-1" href="#building-the-platform"><span class="icon icon-link"></span></a>Building the Platform</h3>
<p>First, create your resources in your Cloud service provider environment.</p>
<ol>
<li>Create all resources with the following tags.
<ul>
<li>Department - Finance</li>
<li>Environment - Development</li>
</ul>
</li>
<li>Create a new storage resource with the hierarchical namespace enabled.
<ul>
<li>Add a container/bucket called <strong>datalakestore</strong>.</li>
</ul>
</li>
<li>Create the following ETL resource applicable to your Cloud service provider environment.
<ul>
<li>Azure - Azure Data Factory</li>
<li>AWS - Glue Data Pipeline</li>
<li>GCP - Cloud Data Fusion</li>
</ul>
</li>
<li>Create the following encryption resource to your Cloud service provider environment.
<ul>
<li>Azure - Azure Key Vault</li>
<li>AWS - Key Management Service</li>
<li>GCP - Secret Manager</li>
</ul>
</li>
<li>Create a new SQL PaaS database called <strong>DataMart</strong>.
<ul>
<li>The database size should be 20GB.</li>
</ul>
</li>
</ol>
<h3 id="ingestion"><a aria-hidden="true" tabindex="-1" href="#ingestion"><span class="icon icon-link"></span></a>Ingestion</h3>
<p>The source data you will be using is the <a rel="external" href="http://www.fuelwatch.wa.gov.au/fuelwatch/fuelWatchRSS">FuelWatch RSS feed</a> from the Western Australian Government.</p>
<ol>
<li>Copy the storage resource key/secrets for the storage and save it in the deployed encryption resource.
<ul>
<li>Use the name <strong>dataLakeStorageAccountKey</strong> or similar as the secret name.</li>
</ul>
</li>
<li>Ingest the RSS feed into the into the <strong>datalakestore</strong> in the storage account deployed above.
<ul>
<li><strong><em>Hint:</em></strong> You can use the HTTP linked service and an XML file type as the dataset type.</li>
</ul>
</li>
<li>Import the item array with all related fields into a parquet file in the storage account with the path below.
<ul>
<li>datalakestore/Raw/FuelWatch/.</li>
<li>The file name should be <strong>feed.parquet</strong>.</li>
</ul>
</li>
<li>Once the file has been imported into the data lake, add another activity to the same pipeline which reads the parquet file from the data lake and writes it to the DataMart SQL database.
<ul>
<li>Use a temporary table in the tempstage schema called <strong>FuelPrices</strong>. This activity must run after the activity to import the source data.</li>
<li>The connection to the SQL PaaS database should ideally make use of the identity from the ETL pipeline resource or the secrets from the encryption resource.</li>
</ul>
</li>
</ol>
<h3 id="modelling-1"><a aria-hidden="true" tabindex="-1" href="#modelling-1"><span class="icon icon-link"></span></a>Modelling</h3>
<p>Once the temporary data has been loaded into the data mart, transform the data into fact and dimension tables for our user-consumed data model. All objects should be created in a new schema named <strong>dw</strong>.</p>
<ol>
<li>Create three (3) new dimension tables - <strong>Brand</strong>, <strong>Site</strong> and <strong>SiteFeatures</strong>. They should have the respective attributes below.
<ul>
<li>BrandID (Identity, clustered primary key), BrandName</li>
<li>SiteID (Identity, clustered primary key), TradingName, Location, Address, Phone, Latitude, Longitude. Add a computed, persisted column named FullAddress which combines Address and Location.</li>
<li>SiteFeatureID (Identity, clustered primary key), SiteID (From the Site table) and the various site features from the delimited source column site-features.</li>
</ul>
</li>
<li>Create a single fact table called <strong>FuelPrice</strong>. It should have the columns below:
<ul>
<li>FuelPriceID (Identity), BrandID (From the Branch table), SiteID (From the Site table), DateID (Numeric and stored as yyyymmdd), Price, DateCreated (Default to current system time) and DateModified (nullable, no default).</li>
</ul>
</li>
<li>Add a primary key across the SiteID, BrandID and DateID columns and a clustered index on the DateID column.
<ul>
<li>The naming convention for the index should be <code>IDX_&#x3C;Table Name>_&#x3C;Column Name></code>.</li>
</ul>
</li>
<li>Create appropriate artefacts, scripts or pipelines to populate the tables above.
<ul>
<li>Keep these artefacts handy for the technical interview.</li>
</ul>
</li>
</ol>
<h2 id="completion-1"><a aria-hidden="true" tabindex="-1" href="#completion-1"><span class="icon icon-link"></span></a>Completion</h2>
<p>When the solution is above is complete, save any artefacts created into a source code repository (E.g. GitHub) and share this repository (or artefacts) with the Consultant/ Talent Acquisition Specialist who contacted you from Telstra Purple. If also possible, please keep your Cloud service provider environment running until the in-person technical interview has been conducted or as otherwise advised.</p><!-- HTML_TAG_END --></article></div>
<button id="scrollToTopButton" class="fixed bottom-5 right-7 bg-red text-white p-3 text-lg rounded-xl hidden">Top</button></div>



			<script type="application/json" data-type="svelte-data" data-url="/index.json">{"status":200,"statusText":"","headers":{"content-type":"text/plain;charset=UTF-8"},"body":"[{\"metadata\":{\"title\":\"Cloud\",\"interviews\":\"Azure Cloud,AWS Cloud\",\"sortorder\":1},\"slug\":\"cloud\"},{\"metadata\":{\"title\":\"Data\",\"interviews\":\"Data Analyst,Data Engineer\",\"sortorder\":2},\"slug\":\"data\"},{\"metadata\":{\"title\":\"Development\",\"interviews\":\"Toy Robot\",\"sortorder\":3},\"slug\":\"development\"},{\"metadata\":{\"title\":\"DevOps\",\"interviews\":\"Automation Specialist\",\"sortorder\":4},\"slug\":\"devops\"}]"}</script>

	<script type="application/json" data-type="svelte-data" data-url="/data.json">{"status":200,"statusText":"","headers":{"content-type":"text/plain;charset=UTF-8"},"body":"{\"metadata\":{\"title\":\"Data\",\"interviews\":\"Data Analyst,Data Engineer\",\"sortorder\":2},\"content\":\"\u003Ch1 id=\\\"data-analyst\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#data-analyst\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EData Analyst\u003C\u002Fh1\u003E\\n\u003Ch2 id=\\\"prerequisites\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#prerequisites\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EPrerequisites\u003C\u002Fh2\u003E\\n\u003Cp\u003EIn order to complete this test, you will need:\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003EYour laptop with \u003Ca href=\\\"https:\u002F\u002Fpowerbi.microsoft.com\u002Fen-us\u002Fdownloads\u002F\\\"\u003EPower BI Desktop\u003C\u002Fa\u003E installed.\u003C\u002Fli\u003E\\n\u003Cli\u003EA public GitHub repo, or a Google\u002FOneDrive where you can share your workings (E.g. Power BI files).\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch2 id=\\\"scenario\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#scenario\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EScenario\u003C\u002Fh2\u003E\\n\u003Cp\u003EAs the Data Analyst for a small fuel company, you have been given two (2) data sources.\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003E\u003Ca href=\\\"http:\u002F\u002Fwww.fuelwatch.wa.gov.au\u002Ffuelwatch\u002FfuelWatchRSS\\\"\u003EThe FuelWatch RSS feed\u003C\u002Fa\u003E\u003C\u002Fli\u003E\\n\u003Cli\u003E\u003Ca href=\\\"\u002Fcode\u002Fdiscount.xlsx\\\"\u003EDiscounts Excel file\u003C\u002Fa\u003E\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch2 id=\\\"instructions\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#instructions\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EInstructions\u003C\u002Fh2\u003E\\n\u003Cp\u003EYou have been ask to create a Power BI report that combines both sources to answer questions the business may have around its competitors.\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"modelling\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#modelling\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EModelling\u003C\u002Fh3\u003E\\n\u003Col\u003E\\n\u003Cli\u003EIn Power BI, connect to the two (2) data sources.\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate three (3) new dimension tables - \u003Cstrong\u003EBrand\u003C\u002Fstrong\u003E, \u003Cstrong\u003ESite\u003C\u002Fstrong\u003E and \u003Cstrong\u003ESiteFeatures\u003C\u002Fstrong\u003E. They should have the respective attributes below.\\n\u003Cul\u003E\\n\u003Cli\u003EBrandID , BrandName\u003C\u002Fli\u003E\\n\u003Cli\u003ESiteID , TradingName, Location, Address, Phone, Latitude, Longitude. Please also add a computed, persisted column named \u003Cstrong\u003E\u003Cem\u003EFullAddress\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E which combines Address and Location.\u003C\u002Fli\u003E\\n\u003Cli\u003ESiteFeatureID , SiteID (From the Site table) and the various site features from the delimited source column site-features.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate a single fact table called FuelPrice. It should have the columns below:\\n\u003Cul\u003E\\n\u003Cli\u003EFuelPriceID (Identity), BrandID (From the Branch table), SiteID (From the Site table), DateID (Numeric and stored as yyyymmdd), Price, DateCreated (Default to current system time) and DateModified (nullable, no default).\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EClean the data in Power BI by removing any uncesscary columns not mentioned above.\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch3 id=\\\"visualisation\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#visualisation\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EVisualisation\u003C\u002Fh3\u003E\\n\u003Col\u003E\\n\u003Cli\u003ECreate visuals using the modelled data that allow the business to answer the following questions.\\n\u003Cul\u003E\\n\u003Cli\u003EWhen and where can they find the cheapest fuel after the is discount applied?\u003C\u002Fli\u003E\\n\u003Cli\u003ESee a list of the top 10 sites with the cheapest fuel price?\u003C\u002Fli\u003E\\n\u003Cli\u003EBe able to drill-down into all the details for a the top 10 cheapest fuel stations?\u003C\u002Fli\u003E\\n\u003Cli\u003EDiscover quickly which sites are open 24 hours a day?\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Cp\u003EThe business executives have also asked for how a consistent theme can be applied to the report and other reports in the future.\u003C\u002Fp\u003E\\n\u003Ch2 id=\\\"completion\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#completion\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ECompletion\u003C\u002Fh2\u003E\\n\u003Cp\u003EWhen the solution is above is complete, save the PowerBI file and any supporting templates and share with the Consultant\u002F Talent Acquisition Specialist who contacted you from Telstra Purple.\u003C\u002Fp\u003E\\n\u003Ch1 id=\\\"data-engineer\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#data-engineer\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EData Engineer\u003C\u002Fh1\u003E\\n\u003Ch2 id=\\\"prerequisites-1\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#prerequisites-1\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EPrerequisites\u003C\u002Fh2\u003E\\n\u003Cp\u003EPlease build the platform on the cloud environment as nominated by the Consultant\u002F Talent Acquisition Specialist who has invited you to complete this test.\u003C\u002Fp\u003E\\n\u003Cp\u003ETo complete this test, you will need:\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003EAccess to a Cloud service provider environment.\\n\u003Cul\u003E\\n\u003Cli\u003EFor an Azure Subscription, you can create a \u003Ca href=\\\"https:\u002F\u002Fazure.microsoft.com\u002Fen-au\u002Ffree\u002F\\\"\u003E30-day free trial\u003C\u002Fa\u003E if you don't have an Azure subscription.\u003C\u002Fli\u003E\\n\u003Cli\u003EFor an AWS Account, you can utilise \u003Ca href=\\\"https:\u002F\u002Faws.amazon.com\u002Ffree\u002F\\\"\u003EAWS free tier\u003C\u002Fa\u003E if you don't have an AWS Account.\u003C\u002Fli\u003E\\n\u003Cli\u003EFor an GCP Environment, you can utilise \u003Ca href=\\\"https:\u002F\u002Fcloud.google.com\u002Ffree\\\"\u003EGCP free tier\u003C\u002Fa\u003E if you don't have an GCP Account.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EYour laptop with your tools\u002F IDE that you like to work with.\u003C\u002Fli\u003E\\n\u003Cli\u003EA public GitHub repo, or a Google\u002FOneDrive where you can share your workings.\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch2 id=\\\"scenario-1\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#scenario-1\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EScenario\u003C\u002Fh2\u003E\\n\u003Cp\u003EWe are assisting a customer in building out a solution which ingests the latest fuel prices from the Fuel Watch RSS feed. This data is not in a great structure, and we would like to ingest this data into a data lake, perform some transformations and build out a data mart for use in Power BI, the customers visualisation tool of choice.\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003EOur customer would like to take an infrastructure-as-code approach to the deployment of the new resources however, the delivery of a working prototype is the highest priority.\u003C\u002Fli\u003E\\n\u003Cli\u003EAll resources should be deployed in Australia.\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch2 id=\\\"instructions-1\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#instructions-1\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EInstructions\u003C\u002Fh2\u003E\\n\u003Cp\u003EFollow these instructions and deploy using whatever means you feel necessary.\u003C\u002Fp\u003E\\n\u003Ch3 id=\\\"building-the-platform\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#building-the-platform\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EBuilding the Platform\u003C\u002Fh3\u003E\\n\u003Cp\u003EFirst, create your resources in your Cloud service provider environment.\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003ECreate all resources with the following tags.\\n\u003Cul\u003E\\n\u003Cli\u003EDepartment - Finance\u003C\u002Fli\u003E\\n\u003Cli\u003EEnvironment - Development\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate a new storage resource with the hierarchical namespace enabled.\\n\u003Cul\u003E\\n\u003Cli\u003EAdd a container\u002Fbucket called \u003Cstrong\u003Edatalakestore\u003C\u002Fstrong\u003E.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate the following ETL resource applicable to your Cloud service provider environment.\\n\u003Cul\u003E\\n\u003Cli\u003EAzure - Azure Data Factory\u003C\u002Fli\u003E\\n\u003Cli\u003EAWS - Glue Data Pipeline\u003C\u002Fli\u003E\\n\u003Cli\u003EGCP - Cloud Data Fusion\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate the following encryption resource to your Cloud service provider environment.\\n\u003Cul\u003E\\n\u003Cli\u003EAzure - Azure Key Vault\u003C\u002Fli\u003E\\n\u003Cli\u003EAWS - Key Management Service\u003C\u002Fli\u003E\\n\u003Cli\u003EGCP - Secret Manager\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate a new SQL PaaS database called \u003Cstrong\u003EDataMart\u003C\u002Fstrong\u003E.\\n\u003Cul\u003E\\n\u003Cli\u003EThe database size should be 20GB.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch3 id=\\\"ingestion\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#ingestion\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EIngestion\u003C\u002Fh3\u003E\\n\u003Cp\u003EThe source data you will be using is the \u003Ca href=\\\"http:\u002F\u002Fwww.fuelwatch.wa.gov.au\u002Ffuelwatch\u002FfuelWatchRSS\\\"\u003EFuelWatch RSS feed\u003C\u002Fa\u003E from the Western Australian Government.\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003ECopy the storage resource key\u002Fsecrets for the storage and save it in the deployed encryption resource.\\n\u003Cul\u003E\\n\u003Cli\u003EUse the name \u003Cstrong\u003EdataLakeStorageAccountKey\u003C\u002Fstrong\u003E or similar as the secret name.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EIngest the RSS feed into the into the \u003Cstrong\u003Edatalakestore\u003C\u002Fstrong\u003E in the storage account deployed above.\\n\u003Cul\u003E\\n\u003Cli\u003E\u003Cstrong\u003E\u003Cem\u003EHint:\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E You can use the HTTP linked service and an XML file type as the dataset type.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EImport the item array with all related fields into a parquet file in the storage account with the path below.\\n\u003Cul\u003E\\n\u003Cli\u003Edatalakestore\u002FRaw\u002FFuelWatch\u002F.\u003C\u002Fli\u003E\\n\u003Cli\u003EThe file name should be \u003Cstrong\u003Efeed.parquet\u003C\u002Fstrong\u003E.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EOnce the file has been imported into the data lake, add another activity to the same pipeline which reads the parquet file from the data lake and writes it to the DataMart SQL database.\\n\u003Cul\u003E\\n\u003Cli\u003EUse a temporary table in the tempstage schema called \u003Cstrong\u003EFuelPrices\u003C\u002Fstrong\u003E. This activity must run after the activity to import the source data.\u003C\u002Fli\u003E\\n\u003Cli\u003EThe connection to the SQL PaaS database should ideally make use of the identity from the ETL pipeline resource or the secrets from the encryption resource.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch3 id=\\\"modelling-1\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#modelling-1\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003EModelling\u003C\u002Fh3\u003E\\n\u003Cp\u003EOnce the temporary data has been loaded into the data mart, transform the data into fact and dimension tables for our user-consumed data model. All objects should be created in a new schema named \u003Cstrong\u003Edw\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\\n\u003Col\u003E\\n\u003Cli\u003ECreate three (3) new dimension tables - \u003Cstrong\u003EBrand\u003C\u002Fstrong\u003E, \u003Cstrong\u003ESite\u003C\u002Fstrong\u003E and \u003Cstrong\u003ESiteFeatures\u003C\u002Fstrong\u003E. They should have the respective attributes below.\\n\u003Cul\u003E\\n\u003Cli\u003EBrandID (Identity, clustered primary key), BrandName\u003C\u002Fli\u003E\\n\u003Cli\u003ESiteID (Identity, clustered primary key), TradingName, Location, Address, Phone, Latitude, Longitude. Add a computed, persisted column named FullAddress which combines Address and Location.\u003C\u002Fli\u003E\\n\u003Cli\u003ESiteFeatureID (Identity, clustered primary key), SiteID (From the Site table) and the various site features from the delimited source column site-features.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate a single fact table called \u003Cstrong\u003EFuelPrice\u003C\u002Fstrong\u003E. It should have the columns below:\\n\u003Cul\u003E\\n\u003Cli\u003EFuelPriceID (Identity), BrandID (From the Branch table), SiteID (From the Site table), DateID (Numeric and stored as yyyymmdd), Price, DateCreated (Default to current system time) and DateModified (nullable, no default).\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003EAdd a primary key across the SiteID, BrandID and DateID columns and a clustered index on the DateID column.\\n\u003Cul\u003E\\n\u003Cli\u003EThe naming convention for the index should be \u003Ccode\u003EIDX_&#x3C;Table Name\u003E_&#x3C;Column Name\u003E\u003C\u002Fcode\u003E.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003Cli\u003ECreate appropriate artefacts, scripts or pipelines to populate the tables above.\\n\u003Cul\u003E\\n\u003Cli\u003EKeep these artefacts handy for the technical interview.\u003C\u002Fli\u003E\\n\u003C\u002Ful\u003E\\n\u003C\u002Fli\u003E\\n\u003C\u002Fol\u003E\\n\u003Ch2 id=\\\"completion-1\\\"\u003E\u003Ca aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\" href=\\\"#completion-1\\\"\u003E\u003Cspan class=\\\"icon icon-link\\\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003ECompletion\u003C\u002Fh2\u003E\\n\u003Cp\u003EWhen the solution is above is complete, save any artefacts created into a source code repository (E.g. GitHub) and share this repository (or artefacts) with the Consultant\u002F Talent Acquisition Specialist who contacted you from Telstra Purple. If also possible, please keep your Cloud service provider environment running until the in-person technical interview has been conducted or as otherwise advised.\u003C\u002Fp\u003E\"}"}</script>
		</div>
	</body>
</html>
